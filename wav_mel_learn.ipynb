{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml_handsin_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_handimage_bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-990a7b13d4d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mload_handimage_bin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_handimage_bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# keras用のパラメータ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_handimage_bin'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "from load_handimage_bin import load_handimage_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# 数字画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 40, 40\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"handsign.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\",\n",
    "                   \"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\",\n",
    "                   \"./data/m09\", \"./data/m10\", \"./data/m11\", \"./data/m12\",\n",
    "                    \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "digits = datasets.load_digits()\n",
    "(X, y), (x_test, y_test) = mnist.load_data()\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(X)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_handimage_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAVつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "from load_wavimage_bin import load_wavimage_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# 数字画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 701\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"handsign.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./dataset\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_wavimage_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
