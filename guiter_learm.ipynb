{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import skimage\n",
    "#from skimage import io\n",
    "\n",
    "\n",
    "# def scale_minmax(X, min=0.0, max=1.0):\n",
    "#     X_std = (X - X.min()) / (X.max() - X.min())\n",
    "#     X_scaled = X_std * (max - min) + min\n",
    "#     return X_scaled\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    x = 0\n",
    "    #オーディオファイルの読み込み\n",
    "    music, fs = librosa.audio.load(soundpath + filename)\n",
    "    #フーリエ変換\n",
    "    D = librosa.stft(music)\n",
    "    #メルスペクトログラム変換\n",
    "    mfccs = librosa.feature.melspectrogram(D, sr=fs, n_mels=128)\n",
    "    #データ内容をGAIN(db)に変換\n",
    "    mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "    #無音部分の除去\n",
    "    mfccspw = (mfccspw[:, np.any(mfccspw > -40, axis=0)])\n",
    "\n",
    "    for i in np.arange(0, len(mfccspw[1])-10, 10):\n",
    "\n",
    "        split = mfccspw[:,i:i+10]\n",
    "        \n",
    "        # save as PNG\n",
    "        img = split.astype(np.uint8)\n",
    "        matplotlib.image.imsave(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "\n",
    "#        cv2.imwrite(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "        x +=1\n",
    "soundpath = './guiter_wav/6/'\n",
    "savepath = './guiter_wav_image10/6/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "#from sklearn import datasets\n",
    "from sklearn import utils\n",
    "import cv2\n",
    "from PIL import Image\n",
    " \n",
    "IMAGE_SIZE_X = 10\n",
    "IMAGE_SIZE_Y = 10\n",
    "COLOR_BYTE = 3\n",
    "#COLOR_BYTE = 1\n",
    "CATEGORY_NUM = 6\n",
    "threshhold = 80\n",
    " \n",
    "## ラベル名(0～)を付けたディレクトリに分類されたイメージファイルを読み込む\n",
    "## 入力パスはラベル名の上位のディレクトリ\n",
    "def load_split_bin(path):\n",
    "    # ファイル一覧を取得\n",
    "    files1 = glob.glob(os.path.join(path, '*/*.png'))\n",
    "    files = []\n",
    "    for i in files1:\n",
    "        #大きいファイルを開いて\n",
    "        gazo1 = Image.open(i)\n",
    "        #resizeして\n",
    "        gazo2 = gazo1.resize((IMAGE_SIZE_X,IMAGE_SIZE_Y))\n",
    "  \n",
    "        #filesに追加\n",
    "        files.append(gazo2)\n",
    "\n",
    "    # イメージとラベル領域を確保\n",
    "    #images = np.ndarray((len(files), IMAGE_SIZE, IMAGE_SIZE,\n",
    "    #                      COLOR_BYTE), dtype = np.uint8)\n",
    "    images = np.ndarray((len(files), IMAGE_SIZE_X, IMAGE_SIZE_Y)\n",
    "                       , dtype = np.uint8)\n",
    "\n",
    "    labels = np.ndarray(len(files), dtype=np.int)\n",
    "\n",
    "    # イメージとラベルを読み込み\n",
    "    for idx, file in enumerate(files):\n",
    "        # イメージ読み込み\n",
    "        img = io.imread(file)\n",
    "        # ディレクトリ名よりラベルを取得\n",
    "        label = os.path.split(os.path.dirname(file))[-1]\n",
    "        labels[idx] = int(label)\n",
    "\n",
    "        # scikit-learn の他のデータセットの形式に合わせる\n",
    "        flat_data = images.reshape((-1, IMAGE_SIZE_X * IMAGE_SIZE_Y * COLOR_BYTE))\n",
    "        images = flat_data.view()\n",
    "    return utils.Bunch(data=images,\n",
    "                 target=labels.astype(np.int),\n",
    "                 target_names=np.arange(CATEGORY_NUM),\n",
    "                 images=images,\n",
    "                 DESCR=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot understand given URI: <PIL.Image.Image image mode=RGBA size=100x100 at 0x7F18A8....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-06775f07264c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_for_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_for_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_split_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7274e808a809>\u001b[0m in \u001b[0;36mload_split_bin\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# イメージ読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;31m# ディレクトリ名よりラベルを取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                (plugin, kind))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_r\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0muri_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muri_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot understand given URI: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0muri_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# Check if this is supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot understand given URI: <PIL.Image.Image image mode=RGBA size=100x100 at 0x7F18A8...."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "# keras用のパラメータ\n",
    "batch_size =  64\n",
    "#epochs = 500\n",
    "epochs = 40\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 100, 100\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "\n",
    "paths_for_train = [\"./guiter_wav_image/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_split_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_bin(path):\n",
    "    # ファイル一覧を取得\n",
    "    files = glob.glob(os.path.join(path, '*/*.png'))\n",
    "\n",
    "    # イメージとラベル領域を確保\n",
    "    images = np.ndarray((len(files), IMAGE_SIZE_X, IMAGE_SIZE_Y,\n",
    "                          COLOR_BYTE), dtype = np.uint8)\n",
    "    #images = np.ndarray((len(files), IMAGE_SIZE_X, IMAGE_SIZE_Y)\n",
    "    #                   , dtype = np.uint8)\n",
    "\n",
    "    labels = np.ndarray(len(files), dtype=np.int)\n",
    "\n",
    "    # イメージとラベルを読み込み\n",
    "    for idx, file in enumerate(files):\n",
    "        # イメージ読み込み\n",
    "        img = io.imread(file)\n",
    "        # ディレクトリ名よりラベルを取得\n",
    "        label = os.path.split(os.path.dirname(file))[-1]\n",
    "        labels[idx] = int(label)\n",
    "\n",
    "        # scikit-learn の他のデータセットの形式に合わせる\n",
    "    flat_data = images.reshape((-1, IMAGE_SIZE_X * IMAGE_SIZE_Y * COLOR_BYTE))\n",
    "    images = flat_data.view()\n",
    "    return utils.Bunch(data=images,\n",
    "                 target=labels.astype(np.int),\n",
    "                 target_names=np.arange(CATEGORY_NUM),\n",
    "                 images=images,\n",
    "                 DESCR=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3206 samples, validate on 357 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 22.9242 - accuracy: 0.1628 - val_loss: 2.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.9496 - accuracy: 0.1740 - val_loss: 2.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.9657 - accuracy: 0.1747 - val_loss: 2.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.9260 - accuracy: 0.1734 - val_loss: 2.1803 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.9735 - accuracy: 0.1784 - val_loss: 2.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.9469 - accuracy: 0.1756 - val_loss: 2.2970 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.9775 - accuracy: 0.1737 - val_loss: 2.3543 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.9049 - accuracy: 0.1750 - val_loss: 2.4105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.9268 - accuracy: 0.1759 - val_loss: 2.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.9199 - accuracy: 0.1759 - val_loss: 2.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.8964 - accuracy: 0.1750 - val_loss: 2.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.8944 - accuracy: 0.1750 - val_loss: 2.6112 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.8925 - accuracy: 0.1750 - val_loss: 2.6577 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.8910 - accuracy: 0.1750 - val_loss: 2.7020 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.8896 - accuracy: 0.1750 - val_loss: 2.7398 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.8886 - accuracy: 0.1728 - val_loss: 2.7746 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.8987 - accuracy: 0.1669 - val_loss: 2.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.8993 - accuracy: 0.1653 - val_loss: 2.8424 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.8881 - accuracy: 0.1719 - val_loss: 2.8697 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.8858 - accuracy: 0.1666 - val_loss: 2.8997 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.8853 - accuracy: 0.1765 - val_loss: 2.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.8849 - accuracy: 0.1659 - val_loss: 2.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      " - 5s - loss: 1.8845 - accuracy: 0.1765 - val_loss: 2.9814 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      " - 5s - loss: 1.8842 - accuracy: 0.1631 - val_loss: 3.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.8839 - accuracy: 0.1728 - val_loss: 3.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.8838 - accuracy: 0.1728 - val_loss: 3.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      " - 5s - loss: 1.8836 - accuracy: 0.1728 - val_loss: 3.0592 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.8835 - accuracy: 0.1765 - val_loss: 3.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.8834 - accuracy: 0.1753 - val_loss: 3.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.8833 - accuracy: 0.1765 - val_loss: 3.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.8832 - accuracy: 0.1765 - val_loss: 3.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.8831 - accuracy: 0.1765 - val_loss: 3.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.8831 - accuracy: 0.1765 - val_loss: 3.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.8830 - accuracy: 0.1765 - val_loss: 3.1487 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.8830 - accuracy: 0.1728 - val_loss: 3.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      " - 5s - loss: 1.8830 - accuracy: 0.1765 - val_loss: 3.1610 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      " - 5s - loss: 1.8830 - accuracy: 0.1759 - val_loss: 3.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      " - 7s - loss: 1.8830 - accuracy: 0.1765 - val_loss: 3.1711 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      " - 5s - loss: 1.8830 - accuracy: 0.1765 - val_loss: 3.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      " - 5s - loss: 1.8829 - accuracy: 0.1765 - val_loss: 3.1841 - val_accuracy: 0.0000e+00\n",
      "正解率\n",
      "15.885489755823745\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from load_split_bin import load_split_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size =  64\n",
    "#epochs = 500\n",
    "epochs = 40\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 10\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "\n",
    "paths_for_train = [\"./guiter_wav_image10/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_split_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
