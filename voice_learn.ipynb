{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voice_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 件を処理しました\n",
      "20 件を処理しました\n",
      "30 件を処理しました\n",
      "40 件を処理しました\n",
      "50 件を処理しました\n",
      "60 件を処理しました\n",
      "70 件を処理しました\n",
      "80 件を処理しました\n",
      "90 件を処理しました\n",
      "100 件を処理しました\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import skimage\n",
    "#from skimage import io\n",
    "\n",
    "\n",
    "# def scale_minmax(X, min=0.0, max=1.0):\n",
    "#     X_std = (X - X.min()) / (X.max() - X.min())\n",
    "#     X_scaled = X_std * (max - min) + min\n",
    "#     return X_scaled\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    x = 0\n",
    "    #オーディオファイルの読み込み\n",
    "    music, fs = librosa.audio.load(soundpath + filename)\n",
    "    #フーリエ変換\n",
    "    D = librosa.stft(music)\n",
    "    #GAIN表記に変換\n",
    "    log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    #無音部分の除去\n",
    "    log_power = (log_power[:, np.any(log_power > -40, axis=0)])\n",
    "\n",
    "\n",
    "    for i in np.arange(0, len(log_power[1])-20, 10):\n",
    "\n",
    "        split = log_power[:,i:i+20]\n",
    "        \n",
    "        # save as PNG\n",
    "        img = split.astype(np.uint8)\n",
    "        matplotlib.image.imsave(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "        x +=1\n",
    "soundpath = './dataset/0/'\n",
    "savepath = './save_stft_split/0/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "#from sklearn import datasets\n",
    "from sklearn import utils\n",
    "import cv2\n",
    "from PIL import Image\n",
    " \n",
    "IMAGE_SIZE_X = 20\n",
    "IMAGE_SIZE_Y = 1025\n",
    "COLOR_BYTE = 3\n",
    "#COLOR_BYTE = 1\n",
    "CATEGORY_NUM = 6\n",
    "threshhold = 80\n",
    " \n",
    "## ラベル名(0～)を付けたディレクトリに分類されたイメージファイルを読み込む\n",
    "## 入力パスはラベル名の上位のディレクトリ\n",
    "def load_split_bin(path):\n",
    "    # ファイル一覧を取得\n",
    "    files = glob.glob(os.path.join(path, '*/*.png'))\n",
    "\n",
    "    # イメージとラベル領域を確保\n",
    "    images = np.ndarray((len(files), IMAGE_SIZE_X, IMAGE_SIZE_Y,\n",
    "                          COLOR_BYTE), dtype = np.uint8)\n",
    "    #images = np.ndarray((len(files), IMAGE_SIZE_X, IMAGE_SIZE_Y)\n",
    "    #                   , dtype = np.uint8)\n",
    "\n",
    "    labels = np.ndarray(len(files), dtype=np.int)\n",
    "\n",
    "    # イメージとラベルを読み込み\n",
    "    for idx, file in enumerate(files):\n",
    "        # イメージ読み込み\n",
    "        img = io.imread(file)\n",
    "        # ディレクトリ名よりラベルを取得\n",
    "        label = os.path.split(os.path.dirname(file))[-1]\n",
    "        labels[idx] = int(label)\n",
    "\n",
    "        # scikit-learn の他のデータセットの形式に合わせる\n",
    "    flat_data = images.reshape((-1, IMAGE_SIZE_X * IMAGE_SIZE_Y * COLOR_BYTE))\n",
    "    images = flat_data.view()\n",
    "    return utils.Bunch(data=images,\n",
    "                 target=labels.astype(np.int),\n",
    "                 target_names=np.arange(CATEGORY_NUM),\n",
    "                 images=images,\n",
    "                 DESCR=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 5095 samples, validate on 567 samples\n",
      "Epoch 1/40\n",
      " - 140s - loss: 1.0844 - accuracy: 0.4349 - val_loss: 1.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      " - 136s - loss: 1.0661 - accuracy: 0.4336 - val_loss: 1.3313 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      " - 140s - loss: 1.0562 - accuracy: 0.4336 - val_loss: 1.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      " - 128s - loss: 1.0506 - accuracy: 0.4336 - val_loss: 1.4798 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      " - 127s - loss: 1.0474 - accuracy: 0.4336 - val_loss: 1.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      " - 134s - loss: 1.0457 - accuracy: 0.4336 - val_loss: 1.5687 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      " - 146s - loss: 1.0448 - accuracy: 0.4336 - val_loss: 1.5972 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      " - 133s - loss: 1.0442 - accuracy: 0.4336 - val_loss: 1.6213 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      " - 130s - loss: 1.0440 - accuracy: 0.4336 - val_loss: 1.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      " - 147s - loss: 1.0438 - accuracy: 0.4336 - val_loss: 1.6486 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      " - 133s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6565 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      " - 131s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6637 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      " - 126s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      " - 126s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      " - 133s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      " - 126s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6735 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      " - 125s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      " - 125s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6761 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      " - 132s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6740 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      " - 131s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      " - 137s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      " - 127s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6764 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      " - 128s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6759 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      " - 126s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6769 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      " - 126s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6770 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      " - 125s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6773 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      " - 119s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      " - 120s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      " - 120s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      " - 121s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6798 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      " - 121s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      " - 121s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6780 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      " - 123s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6773 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      " - 117s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6757 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      " - 133s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      " - 129s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6772 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      " - 128s - loss: 1.0437 - accuracy: 0.4336 - val_loss: 1.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "import glob\n",
    "from skimage import io\n",
    "from sklearn import utils\n",
    "import os\n",
    "# keras用のパラメータ\n",
    "batch_size =  64\n",
    "#epochs = 500\n",
    "epochs = 40\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 1025, 20\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "\n",
    "paths_for_train = [\"./save_stft_split/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_split_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
