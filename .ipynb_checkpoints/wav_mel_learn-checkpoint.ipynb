{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml_handsin_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "from load_handimage_bin import load_handimage_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# 数字画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 40, 40\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"handsign.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\",\n",
    "                   \"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\",\n",
    "                   \"./data/m09\", \"./data/m10\", \"./data/m11\", \"./data/m12\",\n",
    "                    \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "digits = datasets.load_digits()\n",
    "(X, y), (x_test, y_test) = mnist.load_data()\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(X)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_handimage_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAVつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# 数字画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 302\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./dataset\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_wavimage_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imageでつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from load_png_bin import load_png_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 10\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./save_wav_image/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_png_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitでつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 5259 samples, validate on 585 samples\n",
      "Epoch 1/40\n",
      " - 14s - loss: 1.0925 - accuracy: 0.3944 - val_loss: 1.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      " - 13s - loss: 1.0819 - accuracy: 0.4140 - val_loss: 1.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      " - 13s - loss: 1.0743 - accuracy: 0.4168 - val_loss: 1.2731 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      " - 14s - loss: 1.0682 - accuracy: 0.4168 - val_loss: 1.3234 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      " - 17s - loss: 1.0635 - accuracy: 0.4168 - val_loss: 1.3690 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      " - 14s - loss: 1.0601 - accuracy: 0.4168 - val_loss: 1.4085 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      " - 13s - loss: 1.0577 - accuracy: 0.4168 - val_loss: 1.4389 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      " - 14s - loss: 1.0561 - accuracy: 0.4168 - val_loss: 1.4669 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      " - 13s - loss: 1.0549 - accuracy: 0.4168 - val_loss: 1.4933 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      " - 13s - loss: 1.0540 - accuracy: 0.4168 - val_loss: 1.5161 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      " - 14s - loss: 1.0533 - accuracy: 0.4168 - val_loss: 1.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      " - 14s - loss: 1.0529 - accuracy: 0.4168 - val_loss: 1.5508 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      " - 14s - loss: 1.0526 - accuracy: 0.4168 - val_loss: 1.5659 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      " - 14s - loss: 1.0524 - accuracy: 0.4168 - val_loss: 1.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      " - 14s - loss: 1.0523 - accuracy: 0.4168 - val_loss: 1.5884 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      " - 13s - loss: 1.0521 - accuracy: 0.4168 - val_loss: 1.5988 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-86c394132b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# モデルの学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# 結果の表示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from load_split_bin import load_split_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size =  128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 20\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "\n",
    "paths_for_train = [\"./save_stft_image/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_split_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm save_wav_image/0/*).png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
