{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml_handsin_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "from load_handimage_bin import load_handimage_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# 数字画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 40, 40\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"handsign.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\",\n",
    "                   \"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\",\n",
    "                   \"./data/m09\", \"./data/m10\", \"./data/m11\", \"./data/m12\",\n",
    "                    \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "digits = datasets.load_digits()\n",
    "(X, y), (x_test, y_test) = mnist.load_data()\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(X)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_handimage_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAVつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.datasets import mnist\n",
    "from load_wavimage_bin import load_wavimage_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# 数字画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 302\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./dataset\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_wavimage_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imageでつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from load_png_bin import load_png_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 20\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./save_wav_image/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_png_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitでつくるお"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1753 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.0982 - accuracy: 0.3542 - val_loss: 1.1117 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.0973 - accuracy: 0.3634 - val_loss: 1.1236 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.0966 - accuracy: 0.3634 - val_loss: 1.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.0960 - accuracy: 0.3634 - val_loss: 1.1446 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      " - 4s - loss: 1.0955 - accuracy: 0.3634 - val_loss: 1.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      " - 4s - loss: 1.0950 - accuracy: 0.3634 - val_loss: 1.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.0946 - accuracy: 0.3634 - val_loss: 1.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      " - 5s - loss: 1.0943 - accuracy: 0.3634 - val_loss: 1.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      " - 4s - loss: 1.0941 - accuracy: 0.3634 - val_loss: 1.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      " - 5s - loss: 1.0938 - accuracy: 0.3634 - val_loss: 1.1923 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      " - 4s - loss: 1.0936 - accuracy: 0.3634 - val_loss: 1.1986 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      " - 4s - loss: 1.0934 - accuracy: 0.3634 - val_loss: 1.2043 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      " - 4s - loss: 1.0933 - accuracy: 0.3634 - val_loss: 1.2097 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.0932 - accuracy: 0.3634 - val_loss: 1.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.0931 - accuracy: 0.3634 - val_loss: 1.2184 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      " - 4s - loss: 1.0930 - accuracy: 0.3634 - val_loss: 1.2233 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      " - 5s - loss: 1.0929 - accuracy: 0.3634 - val_loss: 1.2277 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      " - 5s - loss: 1.0929 - accuracy: 0.3634 - val_loss: 1.2315 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      " - 4s - loss: 1.0928 - accuracy: 0.3634 - val_loss: 1.2348 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      " - 4s - loss: 1.0928 - accuracy: 0.3634 - val_loss: 1.2370 - val_accuracy: 0.0000e+00\n",
      "正解率\n",
      "32.700205338809035\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from load_split_bin import load_split_bin\n",
    "\n",
    "# keras用のパラメータ\n",
    "batch_size = 128\n",
    "#epochs = 500\n",
    "epochs = 20\n",
    "\n",
    "# mel画像のサイズ 縦(row)と横(col)\n",
    "img_rows, img_cols = 128, 20\n",
    "\n",
    "# 学習結果を保存するファイルの決定\n",
    "#if len(sys.argv)==1:\n",
    "#    print('使用法: python ml-10-03-digits-cnn-learn.py 保存ファイル名.h5')\n",
    "#    sys.exit()\n",
    "#savefile = sys.argv[1]\n",
    "savefile = \"mel.h5\"\n",
    "\n",
    "#    paths_for_train = [\"./data/m01\", \"./data/m02\", \"./data/m03\", \"./data/m04\", \"./data/m05\", \n",
    "#                       \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                       \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\",\n",
    "#                       \"./data/m16\"] \n",
    "\n",
    "#paths_for_train = [\"./data/m05\", \"./data/m06\", \"./data/m07\", \"./data/m08\", \"./data/m09\", \"./data/m10\",\n",
    "#                   \"./data/m11\", \"./data/m12\", \"./data/m13\", \"./data/m14\", \"./data/m15\", \"./data/m16\"] \n",
    "\n",
    "paths_for_train = [\"./save_split_image/\"]\n",
    "\n",
    "# 手書き数字のデータをロードし、変数digitsに格納\n",
    "# digits = datasets.load_digits()\n",
    "# (X, y), (x_test, y_test) = mnist.load_data()\n",
    "# X = np.concatenate(data)\n",
    "# y = np.concatenate(label)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(X)\n",
    "# np.random.seed(1)\n",
    "# np.random.shuffle(y)\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(paths_for_train)):\n",
    "    path = paths_for_train[i]\n",
    "    d = load_split_bin(path)\n",
    "    data.append(d.data)\n",
    "    label.append(d.target)\n",
    "X = np.concatenate(data)\n",
    "y = np.concatenate(label)\n",
    "\n",
    "# 特徴量のセットを変数Xに、ターゲットを変数yに格納\n",
    "#X = digits.data\n",
    "#y = digits.target\n",
    "\n",
    "# クラス数の取り出し\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# データXをCNN用の形式に変換\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# ターゲットyをkeras用の形式に変換\n",
    "y_keras = keras.utils.to_categorical(y, n_classes)\n",
    "\n",
    "# 畳み込みニューラルネットワークを定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "# モデルの学習\n",
    "history = model.fit(X, y_keras, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=2)\n",
    "\n",
    "# 結果の表示\n",
    "result = model.predict_classes(X, verbose=0)\n",
    "\n",
    "# データ数をtotalに格納\n",
    "total = len(X)\n",
    "# ターゲット（正解）と予測が一致した数をsuccessに格納\n",
    "success = sum(result==y)\n",
    "\n",
    "# 正解率をパーセント表示\n",
    "print('正解率')\n",
    "print(100.0*success/total)\n",
    "\n",
    "# 学習結果を保存\n",
    "model.save(savefile)\n",
    "\n",
    "# 損失関数のグラフの軸ラベルを設定\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# グラフ縦軸の範囲を0以上と定める\n",
    "plt.ylim(0, max(np.r_[history.history['val_loss'], history.history['loss']]))\n",
    "\n",
    "# 損失関数の時間変化を描画\n",
    "val_loss, = plt.plot(history.history['val_loss'], c='#56B4E9')\n",
    "loss, = plt.plot(history.history['loss'], c='#E69F00')\n",
    "\n",
    "# グラフの凡例（はんれい）を追加\n",
    "plt.legend([loss, val_loss], ['loss', 'val_loss'])\n",
    "\n",
    "# 描画したグラフを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm save_wav_image/0/*).png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
