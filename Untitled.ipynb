{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./testset/fujitou_normal_test/fujitou_normal_002.wav\"\n",
    "y, sr = librosa.load(audio_path,offset=0.0,duration=7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128,n_fft=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(sr)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(S, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.title('mel power spectrogram')\n",
    "plt.colorbar(format='%02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_S = librosa.amplitude_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel',fmax=sr)\n",
    "plt.title('mel power spectrogram')\n",
    "#plt.colorbar(format='%02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(log_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(log_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print([len(v) for v in log_S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data, fs = librosa.audio.load(\"./testset/fujitou_normal_test/fujitou_normal_002.wav\",offset=0.0,duration=7.0)\n",
    "# メル周波数ケプストラムを取得\n",
    "melspecs = librosa.feature.melspectrogram(y=data, sr=fs,\n",
    "                                          n_fft=2048, n_mels=128)\n",
    "mels = librosa.power_to_db(melspecs, ref=np.max)\n",
    "# 可視化\n",
    "librosa.display.specshow(mels,x_axis='time', y_axis='mel', fmax=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MUSIC_NET():\n",
    "    def __init__(self, ):\n",
    "        super(MUSIC_NET, self).__init__(\n",
    "            conv1=L.Convolution2D(in_channels=1, out_channels=16,\n",
    "                                  ksize=(16, 9), stride=4, pad=0,\n",
    "                                  wscale=0.02 * math.sqrt(16 * 9)),\n",
    "            conv2=L.Convolution2D(in_channels=16, out_channels=32,\n",
    "                                  ksize=(5, 3), stride=2, pad=0,\n",
    "                                  wscale=0.02 * math.sqrt(16 * 5 * 3)),\n",
    "            conv3=L.Convolution2D(in_channels=32, out_channels=64,\n",
    "                                  ksize=(3, 3), stride=2, pad=0,\n",
    "                                  wscale=0.02 * math.sqrt(32 * 3 * 3)),\n",
    "            fc4=L.Linear(in_size=64 * 14 * 19, out_size=4096,\n",
    "                         wscale=0.02 * math.sqrt(64 * 14 * 19)),\n",
    "            fc5=L.Linear(in_size=4096, out_size=7, wscale=0.02 * math.sqrt(4096)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        y = self.forward(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        accuracy = F.accuracy(y, t)\n",
    "        return loss, accuracy\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = F.relu(self.conv1(x))\n",
    "        conv2 = F.relu(self.conv2(conv1))\n",
    "        conv3 = F.relu(self.conv3(conv2))\n",
    "        reshape3 = F.dropout(F.reshape(conv3, (-1, 64 * 14 * 19)), ratio=0.5)\n",
    "        fc4 = F.dropout(F.relu(self.fc4(reshape3)), ratio=0.5)\n",
    "        fc5 = self.fc5(fc4)\n",
    "        return fc5\n",
    "\n",
    "    def predict(self, x):\n",
    "        y = self.forward(x)\n",
    "        return F.softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "\n",
    "class READ_DATASET(object):\n",
    "    def __init__(self, wavfile, chunk, length, expected_fs=None):\n",
    "        fs, all_data = read(wavfile)\n",
    "        if expected_fs != None and expected_fs != fs:\n",
    "            print(\"It has difference between expected_fs and fs\")\n",
    "            raise AssertionError\n",
    "\n",
    "        all_data = all_data.astype('float64') - 128.0\n",
    "        all_data /= 128.0\n",
    "\n",
    "        self.all_data = all_data\n",
    "        self.sampling_rate = fs\n",
    "        self.CHUNK = chunk\n",
    "        self.length = length\n",
    "\n",
    "        # ノイズを読み込む\n",
    "        self.noise = np.load('noise/noise.npy')  # 8bit 16000Hz\n",
    "        self.noise = self.noise.astype('float32') / 128.0\n",
    "\n",
    "        # インデックス。初期化時は昇順にしておく\n",
    "        n_bolcks_all = len(self.all_data) - self.CHUNK * self.length - 1\n",
    "        self.indexes = np.linspace(0, n_bolcks_all, int(n_bolcks_all / 5.0)).astype(np.int64)\n",
    "        self.n_blocks = len(self.indexes)\n",
    "\n",
    "        print(\"sampling rate is {}\".format(fs))\n",
    "\n",
    "    def shuffle_indexes(self):\n",
    "        self.indexes = np.random.permutation(len(self.indexes))\n",
    "\n",
    "    # ノイズの追加\n",
    "    def _add_noise(self, data, scale=None):\n",
    "        if scale is None:\n",
    "            scale = np.random.uniform(low=0.001, high=3.0)\n",
    "        start_i = np.random.randint(low=0, high=len(self.noise) - len(data))\n",
    "        noise = self.noise[start_i:(start_i + len(data))]\n",
    "        data_with_noise = data + noise * scale\n",
    "        return data_with_noise\n",
    "\n",
    "    # 音量調整\n",
    "    def _change_volume(self, data, volume=None):\n",
    "        if volume is None:\n",
    "            volume = np.random.uniform(low=0.1, high=1.0)\n",
    "        data_changed_vol = data * volume\n",
    "        return data_changed_vol\n",
    "\n",
    "    # 1個データを取り出す(mel-spec)\n",
    "    def get_one_melspec(self, index):\n",
    "        start_i = self.indexes[index]\n",
    "        data = self.all_data[start_i:(start_i + self.CHUNK * self.length)].copy()\n",
    "\n",
    "        # データの変形\n",
    "        data = self._add_noise(data)  # ノイズ追加\n",
    "        data = self._change_volume(data)  # 音量調節\n",
    "\n",
    "        melspecs = librosa.feature.melspectrogram(y=data, sr=self.sampling_rate,\n",
    "                                                  n_fft=2048, n_mels=256)\n",
    "        return melspecs\n",
    "\n",
    "    # 複数個データを取り出す(mel-spec)\n",
    "    def get_batch_melspec(self, indexes):\n",
    "        melspecs_dataset = list()\n",
    "        for index in indexes:\n",
    "            melspecs = self.get_one_melspec(index)\n",
    "            melspecs_dataset.append(melspecs[np.newaxis, :])\n",
    "        return np.array(melspecs_dataset)\n",
    "\n",
    "def main():\n",
    "    read_dataset = READ_DATASET(wavfile='8bit-16000Hz.wav',\n",
    "                                chunk=1024, length=160, expected_fs=16000)\n",
    "    read_dataset.shuffle_indexes()\n",
    "\n",
    "    melspecs_s = read_dataset.get_batch_melspec(np.arange(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # おなじみpandas\n",
    "import glob  # ファイル名を取得するライブラリ\n",
    "import librosa  # 今回の主役librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ceps = []  # 抽出したMFCCを格納するリスト\n",
    "list_label = []  # 正常(0)、異常(1)ラベルを格納するリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 続いてanormalyのwavを処理\n",
    "filelist = glob.glob('dataset/1/*.wav')  # ワイルドカードでanomaly_*.wavのリストを作成\n",
    "\n",
    "for filename in filelist:\n",
    "    y, sr = librosa.core.load(filename,sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "       \n",
    "    # 複数のローリングウィンドウでそれぞれ20次元のMFCCを得られるので、その平均をとる。\n",
    "    ceps = mfcc.mean(axis=1)    \n",
    "    \n",
    "    # リストに追加\n",
    "    list_ceps.append(ceps)  # 20次元のMFCCを追加\n",
    "    list_label.append(1)  # 異常ラベル(1)を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalのwavを処理\n",
    "filelist = glob.glob('dataset/0/*.wav')  # ワイルドカードでnormal_*.wavのリストを作成\n",
    "\n",
    "for filename in filelist:\n",
    "    y, sr = librosa.core.load(filename,sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    \n",
    "    # 複数のローリングウィンドウでそれぞれ20次元のMFCCを得られるので、その平均をとる。\n",
    "    ceps = mfcc.mean(axis=1)\n",
    "    \n",
    "    # リストに追加\n",
    "    list_ceps.append(ceps)  # 20次元のMFCCを追加\n",
    "    list_label.append(0)  # 正常ラベル(0)を追加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレーム化\n",
    "\n",
    "# 20次元のMFCCのデータフレームを作成\n",
    "df_ceps = pd.DataFrame(list_ceps)  \n",
    "\n",
    "columns_name = []  # カラム名を\"dct+連番\"でつける\n",
    "for i in range(20):\n",
    "    columns_name_temp = 'dct{0}'.format(i)\n",
    "    columns_name.append(columns_name_temp)\n",
    "\n",
    "df_ceps.columns = columns_name\n",
    "\n",
    "# ラベル（正常0、異常1）のデータフレームを作成\n",
    "df_label = pd.DataFrame(list_label, columns=['label'])  \n",
    "\n",
    "# 横にconcat\n",
    "df = pd.concat([df_label, df_ceps], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ぱわー！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "def scale_minmax(X, min=0.0, max=1.0):\n",
    "    X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    return X_scaled\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    # オーディオファイル(au）を読み込む\n",
    "    music, fs = librosa.audio.load(soundpath + filename, offset=0.0, duration=7.0)\n",
    "    # メルスペクトラム（MFCC）変換\n",
    "    mfccs = librosa.feature.melspectrogram(music, sr=fs,n_fft=2048, n_mels=128)\n",
    "    mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "    \n",
    "    # グラフに変換する\n",
    "    im = librosa.display.specshow(mfccspw, sr=fs,cmap=\"gray\")\n",
    "    # PNG形式画像で保存する\n",
    "#    plt.savefig(savepath + filename + '.png',dpi=200)\n",
    "    # min-max scale to fit inside 8-bit range\n",
    "    img = scale_minmax(mfccspw, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "\n",
    "    # save as PNG\n",
    "    skimage.io.imsave(savepath + filename + '.png', img)\n",
    "soundpath = './dataset/0/'\n",
    "savepath = './save_wav_image/0/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割ぱわー！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "# def scale_minmax(X, min=0.0, max=1.0):\n",
    "#     X_std = (X - X.min()) / (X.max() - X.min())\n",
    "#     X_scaled = X_std * (max - min) + min\n",
    "#     return X_scaled\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    x = 0\n",
    "    for i in np.arange(0, 2, 0.2):\n",
    "        # オーディオファイル(au）を読み込む\n",
    "        music, fs = librosa.audio.load(soundpath + filename, offset=i, duration=0.2)\n",
    "        # メルスペクトラム（MFCC）変換\n",
    "        mfccs = librosa.feature.melspectrogram(music, sr=fs, n_mels=128)\n",
    "        #配列データをgain(-80db~0db)に変換\n",
    "        mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "        #無音部分の除去\n",
    "        mfccspw = (mfccspw[:, np.all(mfccspw > -80, axis=0)])\n",
    "        # グラフに変換する\n",
    "#        im = librosa.display.specshow(mfccspw, sr=fs,cmap=\"gray\")\n",
    "        # PNG形式画像で保存する\n",
    "        #plt.savefig(savepath + filename + '.png',dpi=200)\n",
    "        # min-max scale to fit inside 8-bit range\n",
    "#         img = scale_minmax(mfccspw, 0, 255).astype(np.uint8)\n",
    "#        img = mfccspw.astype(np.uint8)\n",
    "#         img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "\n",
    "        # save as PNG\n",
    "        matplotlib.image.imsave(savepath + filename +\"(\"+str(x)+\")\"+ '.png', mfccspw)\n",
    "        x +=1\n",
    "soundpath = './dataset/1/'\n",
    "savepath = './save_split_image/1/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy配列のスライスで分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import skimage\n",
    "#from skimage import io\n",
    "\n",
    "\n",
    "# def scale_minmax(X, min=0.0, max=1.0):\n",
    "#     X_std = (X - X.min()) / (X.max() - X.min())\n",
    "#     X_scaled = X_std * (max - min) + min\n",
    "#     return X_scaled\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    x = 0\n",
    "    #オーディオファイルの読み込み\n",
    "    music, fs = librosa.audio.load(soundpath + filename)\n",
    "    #メルスペクトログラム変換\n",
    "    mfccs = librosa.feature.melspectrogram(music, sr=fs, n_mels=128)\n",
    "    #データ内容をGAIN(db)に変換\n",
    "    mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "    #無音部分の除去\n",
    "    mfccspw = (mfccspw[:, np.all(mfccspw > -80, axis=0)])\n",
    "\n",
    "    for i in np.arange(0, len(mfccspw[1])-10, 10):\n",
    "\n",
    "        split = mfccspw[:,i:i+10]\n",
    "        \n",
    "        # save as PNG\n",
    "        img = split.astype(np.uint8)\n",
    "        matplotlib.image.imsave(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "\n",
    "#        cv2.imwrite(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "        x +=1\n",
    "soundpath = './dataset/2/'\n",
    "savepath = './save_split10_image/2/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    x = 0\n",
    "    #オーディオファイルの読み込み\n",
    "    music, fs = librosa.audio.load(soundpath + filename,offset=1.6)\n",
    "    #フーリエ\n",
    "    D = librosa.stft(music)\n",
    "    #データ内容をGAIN(db)に変換\n",
    "    log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    for i in np.arange(0, len(log_power[1])-1000, 1000):\n",
    "\n",
    "        split = log_power[:,i:i+1000]\n",
    "        \n",
    "        # save as PNG\n",
    "        img = split.astype(np.uint8)\n",
    "        matplotlib.image.imsave(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "\n",
    "#        cv2.imwrite(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "        x +=1\n",
    "soundpath = './guiter_wav/6/'\n",
    "savepath = './guiter_wav_image/6/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "source": [
    "１mfccで分割"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import skimage\n",
    "#from skimage import io\n",
    "\n",
    "\n",
    "# def scale_minmax(X, min=0.0, max=1.0):\n",
    "#     X_std = (X - X.min()) / (X.max() - X.min())\n",
    "#     X_scaled = X_std * (max - min) + min\n",
    "#     return X_scaled\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    x = 0\n",
    "    #オーディオファイルの読み込み\n",
    "    music, fs = librosa.audio.load(soundpath + filename)\n",
    "    #メルスペクトログラム変換\n",
    "    mfccs = librosa.feature.mfcc(music, sr=fs, n_mels=128)\n",
    "    #データ内容をGAIN(db)に変換\n",
    "    mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "    #無音部分の除去\n",
    "    mfccspw = (mfccspw[:, np.all(mfccspw > -80, axis=0)])\n",
    "\n",
    "    for i in np.arange(0, len(mfccspw[1])-10, 10):\n",
    "\n",
    "        split = mfccspw[:,i:i+10]\n",
    "        \n",
    "        # save as PNG\n",
    "        img = split.astype(np.uint8)\n",
    "        matplotlib.image.imsave(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "\n",
    "#        cv2.imwrite(savepath + filename +\"(\"+str(x)+\")\"+ '.png', img)\n",
    "        x +=1\n",
    "soundpath = './dataset/1/'\n",
    "savepath = './save_mfcc_image//'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "    save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "#オーディオファイルの読み込み\n",
    "music, fs = librosa.audio.load(\"./testset/fujitou_normal_test/fujitou_normal_002.wav\")\n",
    "#メルスペクトログラム変換\n",
    "mfccs = librosa.feature.melspectrogram(music, sr=fs)\n",
    "#データ内容をGAIN(db)に変換\n",
    "mfccspw = librosa.power_to_db(mfccs, ref=np.max, top_db=100)\n",
    "#無音部分の除去\n",
    "#ref=np.max)\n",
    "#     #無音部分の除去\n",
    "    mfccspw = (mfccspw[:, np.all(mfccspw > -80, axis=0)])\n",
    "    \n",
    "        for i in np.arange(0, len(mfccspw[1])-10, 10):\n",
    "        \n",
    "                split = mfccspw[:,i:i+10]mfccspw = (mfccspw[:, np.all(mfccspw > -80, axis=0)])\n",
    "librosa.display.specshow(mfccs,x_axis='time', y_axis='mel', fmax=fs)\n",
    "\n",
    "\n",
    "# plt.imshow(mfccs,cmap=plt.cm.gray)\n",
    "# plt.yticks([]) # y軸を消す                                                  \n",
    "# plt.xticks([]) # x軸を消す \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(mfccspw,x_axis='time', y_axis='mel', fmax=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mfccspw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パワーしなかった場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "def save_png(filename,soundpath,savepath):\n",
    "    # オーディオファイル(au）を読み込む\n",
    "    music, fs = librosa.audio.load(soundpath + filename, offset=1.0, duration=7.0)\n",
    "    # メルスペクトラム（MFCC）変換\n",
    "    mfccs = librosa.feature.mfcc(music, sr=fs,n_fft=2048, n_mels=128)\n",
    "    #mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "    \n",
    "    # グラフに変換する\n",
    "    librosa.display.specshow(mfccs, sr=fs,cmap=\"gray\",fmax=fs)\n",
    "\n",
    "    # PNG形式画像で保存する\n",
    "    plt.savefig(savepath + filename + '.png',dpi=200)\n",
    "    \n",
    "\n",
    "soundpath = './dataset/2/'\n",
    "savepath = './dataset_back/no_power_image/2/'\n",
    "cnt = 0\n",
    "for filename in os.listdir(soundpath):\n",
    "    cnt += 1\n",
    "    if((cnt % 10) == 0):\n",
    "        print(cnt,'件を処理しました')\n",
    "save_png(filename,soundpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import IPython\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data, fs = librosa.audio.load(\"./testset/fujitou_normal_test/fujitou_normal_002.wav\")\n",
    "# メル周波数ケプストラムを取得\n",
    "melspecs = librosa.feature.melspectrogram(y=data, sr=fs,\n",
    "                                          n_fft=2048, n_mels=128)\n",
    "mels = librosa.power_to_db(melspecs, ref=np.max)\n",
    "melss = (mels[:, np.all(mels > -80, axis=0)])\n",
    "\n",
    "print(len(melss[:,:10]))\n",
    "\n",
    "# display(IPython.display.Audio(data, rate=fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #オーディオファイルの読み込み\n",
    "    music, fs = librosa.audio.load(soundpath + filename)\n",
    "    #メルスペクトログラム変換\n",
    "    mfccs = librosa.feature.melspectrogram(music, sr=fs, n_mels=128)\n",
    "    #データ内容をGAIN(db)に変換\n",
    "    mfccspw = librosa.power_to_db(mfccs, ref=np.max)\n",
    "    #無音部分の除去\n",
    "    mfccspw = (mfccspw[:, np.all(mfccspw > -80, axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(mfccspw,x_axis='time', y_axis='mel', fmax=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(melss,x_axis='time', y_axis='mel', fmax=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data, fs = librosa.audio.load(\"./dataset_back/akane_normal/akane_normal_097.wav\",\n",
    "                              offset=0.0,duration=7.0)\n",
    "#スプリット練習\n",
    "non_silent_interval = librosa.effects.split(y=data, top_db=1.0, ref=np.max,hop_length=1000)\n",
    "# 可視化\n",
    "plt.plot(data[non_silent_interval[0][0]:non_silent_interval[0][1]])\n",
    "plt.show()\n",
    "# librosa.display.specshow(split,x_axis='time', y_axis='mel', fmax=fs)\n",
    "\n",
    "# メル周波数ケプストラムを取得\n",
    "# melspecs = librosa.feature.melspectrogram(y=data, sr=fs,n_fft=2048, n_mels=128,\n",
    "#                                          hop_length=2048,win_length=2048)\n",
    "# mels = librosa.power_to_db(melspecs, ref=np.max)\n",
    "# # 可視化\n",
    "# librosa.display.specshow(mels,x_axis='time', y_axis='mel', fmax=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = np.array(sound.get_array_of_samples()).astype('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, fs = librosa.audio.load(\"./dataset_back/uemura_normal/uemura_normal_001.wav\",\n",
    "                              offset=3.0,duration=3.99)\n",
    "D = librosa.stft(data)\n",
    "D\n",
    "fig = plt.figure(1, figsize=(12,4)); ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "print(log_power)\n",
    "\n",
    "log_powern = (log_power[:, ~np.all(log_power < -80, axis=0)])\n",
    "print(log_powern)\n",
    "librosa.display.specshow(log_powern,x_axis='time', y_axis='mel', fmax=fs)\n",
    "plt.colorbar()\n",
    "# mel = librosa.feature.melspectrogram(y=data, sr=fs,\n",
    "#                                           n_fft=2048, n_mels=128)\n",
    "# #np.array(data)\n",
    "# data\n",
    "# print(type(mel))\n",
    "# print(mel.shape)\n",
    "# pil_img_gray = Image.fromarray(mel)\n",
    "# print(pil_img_gray.mode)\n",
    "# pil_img_gray.save('teeest.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, fs = librosa.audio.load(\"./guiter_wav/0/am.wav\",offset=1.6,duration=1.99)\n",
    "D = librosa.stft(data)\n",
    "D\n",
    "#fig = plt.figure(1, figsize=(12,4)); ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "librosa.display.specshow(log_power,x_axis='time', y_axis='mel', fmax=fs)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "librosa.display.specshow(log_power, x_axis=\"time\", y_axis=\"log\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(12,4)); ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "librosa.display.specshow(log_power, x_axis=\"time\", y_axis=\"linear\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.effects.split(y, top_db=60, ref=<function amax>, frame_length=2048, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('spleeter': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3dbb125119270d75a70a49e6abc2cb68ff6de13c30636ef30fa1f4ff9a05aaef"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}